+++
abstract = "In a dynamic network, the neighborhood of the vertices evolve across different temporal snapshots of the network. Accurate modeling of this temporal evolution can help solve complex tasks involving real-life social and interaction networks. However, existing models for learning latent representation are inadequate for obtaining the representation vectors of the vertices for different time-stamps of a dynamic network in a meaningful way. In this paper, we propose latent representation learning models for dynamic networks which overcome the above limitation by considering two different kinds of temporal smoothness: (i) retrofitted, and (ii) linear transformation. The retrofitted model tracks the representation vector of a vertex over time, facilitating vertex-based temporal analysis of a network. On the other hand, linear transformation based model provides a smooth transition operator which maps the representation vectors of all vertices from one temporal snapshot to the next (unobserved) snapshot-this facilitates prediction of the state of a network in a future time-stamp. We validate the performance of our proposed models by employing them for solving the temporal link prediction task. Experiments on 9 real-life networks from various domains validate that the proposed models are significantly better than the existing models for predicting the dynamics of an evolving network."
authors = ["Tanay Kumar Saha", "Thomas Williams", "Mohammad Al Hasan", "Shafiq Joty", "Nicholas K. Varberg"]
date = "2018-02-01"
image_preview = ""
math = true
publication_types = ["2"]
publication = "*arXiv*"
publication_short = "In **arXiv**"
selected = true
title = "Models for Capturing Temporal Smoothness in Evolving Networks for Learning Latent Representation of Nodes"
url_code = "https://gitlab.com/tksaha/temporalnode2vec"
url_pdf = "https://arxiv.org/abs/1804.05816"





# Optional featured image (relative to `static/img/` folder).
[header]
#image = "headers/fs3.jpg"

+++

